{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import git\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.models.disc_models import DiscreteDiagSheafDiffusion, DiscreteBundleSheafDiffusion, DiscreteGeneralSheafDiffusion\n",
    "from src.utils.parser import get_parser\n",
    "from src.utils.heterophilic import get_dataset, get_fixed_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_wandb_env():\n",
    "    exclude = {\n",
    "        \"WANDB_PROJECT\",\n",
    "        \"WANDB_ENTITY\",\n",
    "        \"WANDB_API_KEY\",\n",
    "    }\n",
    "    for k, v in os.environ.items():\n",
    "        if k.startswith(\"WANDB_\") and k not in exclude:\n",
    "            del os.environ[k]\n",
    "\n",
    "\n",
    "def train(model, optimizer, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x)[data.train_mask]\n",
    "    nll = F.nll_loss(out, data.y[data.train_mask])\n",
    "    loss = nll\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    del out\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits, accs, losses, preds = model(data.x), [], [], []\n",
    "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "            pred = logits[mask].max(1)[1]\n",
    "            acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "\n",
    "            loss = F.nll_loss(logits[mask], data.y[mask])\n",
    "\n",
    "            preds.append(pred.detach().cpu())\n",
    "            accs.append(acc)\n",
    "            losses.append(loss.detach().cpu())\n",
    "        return accs, preds, losses\n",
    "\n",
    "def run_exp(args, dataset, model_cls, fold):\n",
    "    data = dataset[0]\n",
    "    data = get_fixed_splits(data, args['dataset'], fold)\n",
    "    data = data.to(args['device'])\n",
    "\n",
    "    model = model_cls(data.edge_index, args)\n",
    "    model = model.to(args['device'])\n",
    "\n",
    "    sheaf_learner_params, other_params = model.grouped_parameters()\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': sheaf_learner_params, 'weight_decay': args['sheaf_decay']},\n",
    "        {'params': other_params, 'weight_decay': args['weight_decay']}\n",
    "    ], lr=args['lr'])\n",
    "\n",
    "    epoch = 0\n",
    "    best_val_acc = test_acc = 0\n",
    "    best_val_loss = float('inf')\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    best_epoch = 0\n",
    "    bad_counter = 0\n",
    "    \n",
    "    \n",
    "    total_pred = []\n",
    "    for epoch in range(args['epochs']):\n",
    "        train(model, optimizer, data)\n",
    "\n",
    "        [train_acc, val_acc, tmp_test_acc], preds, [\n",
    "            train_loss, val_loss, tmp_test_loss] = test(model, data)\n",
    "        if fold == 0:\n",
    "            res_dict = {\n",
    "                f'fold{fold}_train_acc': train_acc,\n",
    "                f'fold{fold}_train_loss': train_loss,\n",
    "                f'fold{fold}_val_acc': val_acc,\n",
    "                f'fold{fold}_val_loss': val_loss,\n",
    "                f'fold{fold}_tmp_test_acc': tmp_test_acc,\n",
    "                f'fold{fold}_tmp_test_loss': tmp_test_loss,\n",
    "            }\n",
    "            wandb.log(res_dict, step=epoch)\n",
    "\n",
    "        new_best_trigger = val_acc > best_val_acc if args['stop_strategy'] == 'acc' else val_loss < best_val_loss\n",
    "        if new_best_trigger:\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = val_loss\n",
    "            test_acc = tmp_test_acc\n",
    "            best_epoch = epoch\n",
    "            bad_counter = 0\n",
    "        else:\n",
    "            bad_counter += 1\n",
    "\n",
    "        if bad_counter == args['early_stopping']:\n",
    "            break\n",
    "#haven't tested the following yet        \n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            total_pred.append(preds)\n",
    "            \n",
    "            \n",
    "\n",
    "    print(f\"Fold {fold} | Epochs: {epoch} | Best epoch: {best_epoch}\")\n",
    "    print(f\"Test acc: {test_acc:.4f}\")\n",
    "    print(f\"Best val acc: {best_val_acc:.4f}\")\n",
    "\n",
    "    if \"ODE\" not in args['model']:\n",
    "        # Debugging for discrete models\n",
    "        for i in range(len(model.sheaf_learners)):\n",
    "            L_max = model.sheaf_learners[i].L.detach().max().item()\n",
    "            L_min = model.sheaf_learners[i].L.detach().min().item()\n",
    "            L_avg = model.sheaf_learners[i].L.detach().mean().item()\n",
    "            L_abs_avg = model.sheaf_learners[i].L.detach().abs().mean().item()\n",
    "            print(f\"Laplacian {i}: Max: {L_max:.4f}, Min: {L_min:.4f}, Avg: {L_avg:.4f}, Abs avg: {L_abs_avg:.4f}\")\n",
    "\n",
    "        with np.printoptions(precision=3, suppress=True):\n",
    "            for i in range(0, args['layers']):\n",
    "                print(f\"Epsilons {i}: {model.epsilons[i].detach().cpu().numpy().flatten()}\")\n",
    "\n",
    "    wandb.log({'best_test_acc': test_acc, 'best_val_acc': best_val_acc, 'best_epoch': best_epoch})\n",
    "    keep_running = False if test_acc < args['min_acc'] else True\n",
    "\n",
    "    return test_acc, best_val_acc, keep_running, total_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mila/y/yanlei.zhang/Research/sheaf-neural-network/notebooks/wandb/run-20230320_191034-3q84gtkb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sheafnn/sheafnn/runs/3q84gtkb\" target=\"_blank\">honest-capybara-19</a></strong> to <a href=\"https://wandb.ai/sheafnn/sheafnn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:14<02:13, 14.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 | Epochs: 607 | Best epoch: 407\n",
      "Test acc: 0.7838\n",
      "Best val acc: 0.8136\n",
      "Laplacian 0: Max: 0.0111, Min: -0.0677, Avg: -0.0205, Abs avg: 0.0218\n",
      "Laplacian 1: Max: 0.0149, Min: -0.0746, Avg: -0.0206, Abs avg: 0.0236\n",
      "Laplacian 2: Max: 0.0496, Min: -0.1040, Avg: -0.0221, Abs avg: 0.0294\n",
      "Laplacian 3: Max: 0.0996, Min: -0.1550, Avg: -0.0297, Abs avg: 0.0442\n",
      "Epsilons 0: [1.186 1.192 1.042]\n",
      "Epsilons 1: [1.193 1.197 1.062]\n",
      "Epsilons 2: [1.195 1.208 1.08 ]\n",
      "Epsilons 3: [1.216 1.246 1.097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:32<02:10, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 | Epochs: 759 | Best epoch: 559\n",
      "Test acc: 0.9189\n",
      "Best val acc: 0.8136\n",
      "Laplacian 0: Max: 0.0102, Min: -0.0761, Avg: -0.0239, Abs avg: 0.0255\n",
      "Laplacian 1: Max: 0.0158, Min: -0.0890, Avg: -0.0270, Abs avg: 0.0287\n",
      "Laplacian 2: Max: 0.0335, Min: -0.1305, Avg: -0.0314, Abs avg: 0.0356\n",
      "Laplacian 3: Max: 0.1466, Min: -0.2031, Avg: -0.0320, Abs avg: 0.0427\n",
      "Epsilons 0: [1.263 1.269 1.218]\n",
      "Epsilons 1: [1.276 1.281 1.229]\n",
      "Epsilons 2: [1.294 1.298 1.25 ]\n",
      "Epsilons 3: [1.288 1.288 1.277]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:45<01:44, 14.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 | Epochs: 575 | Best epoch: 375\n",
      "Test acc: 0.8378\n",
      "Best val acc: 0.8814\n",
      "Laplacian 0: Max: 0.0251, Min: -0.0722, Avg: -0.0222, Abs avg: 0.0252\n",
      "Laplacian 1: Max: 0.0339, Min: -0.0975, Avg: -0.0264, Abs avg: 0.0313\n",
      "Laplacian 2: Max: 0.1565, Min: -0.2032, Avg: -0.0273, Abs avg: 0.0480\n",
      "Laplacian 3: Max: 0.2799, Min: -0.5277, Avg: -0.0553, Abs avg: 0.0908\n",
      "Epsilons 0: [1.102 1.214 1.091]\n",
      "Epsilons 1: [1.121 1.202 1.096]\n",
      "Epsilons 2: [1.117 1.215 1.099]\n",
      "Epsilons 3: [1.122 1.217 1.108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:51<01:09, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 | Epochs: 278 | Best epoch: 78\n",
      "Test acc: 0.8378\n",
      "Best val acc: 0.8305\n",
      "Laplacian 0: Max: 0.0436, Min: -0.0924, Avg: -0.0255, Abs avg: 0.0333\n",
      "Laplacian 1: Max: 0.0733, Min: -0.0802, Avg: -0.0157, Abs avg: 0.0283\n",
      "Laplacian 2: Max: 0.1078, Min: -0.1016, Avg: -0.0114, Abs avg: 0.0273\n",
      "Laplacian 3: Max: 0.1819, Min: -0.1844, Avg: -0.0248, Abs avg: 0.0578\n",
      "Epsilons 0: [1.116 0.873 0.963]\n",
      "Epsilons 1: [1.124 0.842 0.934]\n",
      "Epsilons 2: [1.113 0.889 0.966]\n",
      "Epsilons 3: [1.112 0.931 0.964]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:59<00:51, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 | Epochs: 357 | Best epoch: 157\n",
      "Test acc: 0.8108\n",
      "Best val acc: 0.9492\n",
      "Laplacian 0: Max: 0.0477, Min: -0.0902, Avg: -0.0247, Abs avg: 0.0300\n",
      "Laplacian 1: Max: 0.0580, Min: -0.1224, Avg: -0.0270, Abs avg: 0.0382\n",
      "Laplacian 2: Max: 0.2102, Min: -0.3188, Avg: -0.0223, Abs avg: 0.0667\n",
      "Laplacian 3: Max: 0.4530, Min: -0.4419, Avg: 0.0160, Abs avg: 0.0701\n",
      "Epsilons 0: [1.052 1.089 1.088]\n",
      "Epsilons 1: [1.034 1.099 1.101]\n",
      "Epsilons 2: [1.035 1.132 1.11 ]\n",
      "Epsilons 3: [1.028 1.116 1.092]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:08<00:38,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 | Epochs: 369 | Best epoch: 169\n",
      "Test acc: 0.8919\n",
      "Best val acc: 0.9153\n",
      "Laplacian 0: Max: 0.0351, Min: -0.0902, Avg: -0.0236, Abs avg: 0.0276\n",
      "Laplacian 1: Max: 0.0334, Min: -0.0947, Avg: -0.0201, Abs avg: 0.0252\n",
      "Laplacian 2: Max: 0.0683, Min: -0.1080, Avg: -0.0130, Abs avg: 0.0274\n",
      "Laplacian 3: Max: 0.1047, Min: -0.1173, Avg: -0.0103, Abs avg: 0.0249\n",
      "Epsilons 0: [1.086 1.019 1.059]\n",
      "Epsilons 1: [1.105 1.028 1.087]\n",
      "Epsilons 2: [1.125 1.011 1.092]\n",
      "Epsilons 3: [1.115 1.055 1.104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:15<00:26,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 | Epochs: 306 | Best epoch: 106\n",
      "Test acc: 0.9189\n",
      "Best val acc: 0.8305\n",
      "Laplacian 0: Max: 0.0259, Min: -0.0843, Avg: -0.0230, Abs avg: 0.0268\n",
      "Laplacian 1: Max: 0.0388, Min: -0.0796, Avg: -0.0198, Abs avg: 0.0263\n",
      "Laplacian 2: Max: 0.0893, Min: -0.1383, Avg: -0.0320, Abs avg: 0.0476\n",
      "Laplacian 3: Max: 0.6893, Min: -0.8508, Avg: -0.0670, Abs avg: 0.1751\n",
      "Epsilons 0: [0.963 1.    0.954]\n",
      "Epsilons 1: [0.968 1.003 1.005]\n",
      "Epsilons 2: [1.055 1.042 1.018]\n",
      "Epsilons 3: [1.038 1.032 1.052]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:20<00:15,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 | Epochs: 236 | Best epoch: 36\n",
      "Test acc: 0.7297\n",
      "Best val acc: 0.7966\n",
      "Laplacian 0: Max: 0.0616, Min: -0.1023, Avg: -0.0198, Abs avg: 0.0289\n",
      "Laplacian 1: Max: 0.0377, Min: -0.0601, Avg: -0.0135, Abs avg: 0.0207\n",
      "Laplacian 2: Max: 0.1350, Min: -0.1379, Avg: -0.0279, Abs avg: 0.0485\n",
      "Laplacian 3: Max: 0.1144, Min: -0.1324, Avg: -0.0070, Abs avg: 0.0257\n",
      "Epsilons 0: [0.907 0.905 0.811]\n",
      "Epsilons 1: [0.925 0.886 0.85 ]\n",
      "Epsilons 2: [0.899 0.887 0.859]\n",
      "Epsilons 3: [0.936 0.933 0.895]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:36<00:10, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 | Epochs: 710 | Best epoch: 510\n",
      "Test acc: 0.7838\n",
      "Best val acc: 0.9322\n",
      "Laplacian 0: Max: 0.0235, Min: -0.0739, Avg: -0.0223, Abs avg: 0.0250\n",
      "Laplacian 1: Max: 0.0320, Min: -0.0791, Avg: -0.0235, Abs avg: 0.0281\n",
      "Laplacian 2: Max: 0.0506, Min: -0.0891, Avg: -0.0193, Abs avg: 0.0294\n",
      "Laplacian 3: Max: 0.1273, Min: -0.1520, Avg: -0.0126, Abs avg: 0.0373\n",
      "Epsilons 0: [1.207 1.276 1.253]\n",
      "Epsilons 1: [1.221 1.292 1.259]\n",
      "Epsilons 2: [1.207 1.318 1.238]\n",
      "Epsilons 3: [1.274 1.335 1.267]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:46<00:00, 10.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 | Epochs: 437 | Best epoch: 237\n",
      "Test acc: 0.8108\n",
      "Best val acc: 0.8136\n",
      "Laplacian 0: Max: 0.0144, Min: -0.0871, Avg: -0.0232, Abs avg: 0.0257\n",
      "Laplacian 1: Max: 0.0216, Min: -0.1036, Avg: -0.0193, Abs avg: 0.0229\n",
      "Laplacian 2: Max: 0.0624, Min: -0.0875, Avg: -0.0135, Abs avg: 0.0272\n",
      "Laplacian 3: Max: 0.0964, Min: -0.1046, Avg: -0.0073, Abs avg: 0.0244\n",
      "Epsilons 0: [1.113 1.018 1.055]\n",
      "Epsilons 1: [1.12  1.042 1.084]\n",
      "Epsilons 2: [1.142 1.04  1.1  ]\n",
      "Epsilons 3: [1.147 1.06  1.105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#first loss\n",
    "\n",
    "# setup the parameters\n",
    "parser = get_parser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "sha = repo.head.object.hexsha\n",
    "\n",
    "#rewrite and add some parameters\n",
    "args.d = 3\n",
    "args.layers = 4\n",
    "args.dropout = 0.7\n",
    "args.dataset = \"texas\"\n",
    "args.model = \"BundleSheaf\"\n",
    "args.entity = \"sheafnn\"\n",
    "\n",
    "dataset = get_dataset(args.dataset)\n",
    "\n",
    "args.graph_size = dataset[0].x.size(0)\n",
    "args.input_dim = dataset.num_features\n",
    "args.output_dim = dataset.num_classes\n",
    "args.device = torch.device(f'cuda:{args.cuda}' if torch.cuda.is_available() else 'cpu')\n",
    "assert args.normalised or args.deg_normalised\n",
    "if args.sheaf_decay is None:\n",
    "    args.sheaf_decay = args.weight_decay\n",
    "\n",
    "\n",
    "if args.model == 'DiagSheafODE':\n",
    "    model_cls = DiagSheafDiffusion\n",
    "elif args.model == 'BundleSheafODE':\n",
    "    model_cls = BundleSheafDiffusion\n",
    "elif args.model == 'GeneralSheafODE':\n",
    "    model_cls = GeneralSheafDiffusion\n",
    "elif args.model == 'DiagSheaf':\n",
    "    model_cls = DiscreteDiagSheafDiffusion\n",
    "elif args.model == 'BundleSheaf':\n",
    "    model_cls = DiscreteBundleSheafDiffusion\n",
    "elif args.model == 'GeneralSheaf':\n",
    "    model_cls = DiscreteGeneralSheafDiffusion\n",
    "else:\n",
    "    raise ValueError(f'Unknown model')\n",
    "\n",
    "\n",
    "# Set the seed for everything\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "results = []\n",
    "\n",
    "import wandb\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'sheafnn_notebook'\n",
    "wandb.init(project=\"sheafnn\", config=vars(args), entity=args.entity)\n",
    "    \n",
    "#train the diffusion process\n",
    "\n",
    "\n",
    "for fold in tqdm(range(args.folds)):\n",
    "        test_acc, best_val_acc, keep_running, predictions = run_exp(wandb.config, dataset, model_cls, fold)\n",
    "        results.append([test_acc, best_val_acc])\n",
    "        if not keep_running:\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c497e0aabd934fcd81db794855dbeaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>▂▃█▂▂▄▁▁▇█</td></tr><tr><td>best_test_acc</td><td>▂█▃▄▄▇▄▁▂█</td></tr><tr><td>best_val_acc</td><td>▁▂▄▄█▇▄▄▇▃</td></tr><tr><td>fold0_tmp_test_acc</td><td>▁▂▂▂▄▇█▇▇█▇▆▇▆██▇▇▇███▇▇▆▇▇▇▇█▆▇▇▇▇▇▇█▇█</td></tr><tr><td>fold0_tmp_test_loss</td><td>█▆▄▄▃▂▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▃▃▃▅▄▃▃▃▃▄▃▄</td></tr><tr><td>fold0_train_acc</td><td>▁▁▁▄▄▇██████████████████████████████████</td></tr><tr><td>fold0_train_loss</td><td>█▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold0_val_acc</td><td>▁▁▁▂▂▅▇▇▇▇▆▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇</td></tr><tr><td>fold0_val_loss</td><td>█▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▂▂▂▁▂▁▁▂▂▂▁▂▂▁▂▂▂▂▁▁▂▂▂▂</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_acc_std</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>277</td></tr><tr><td>best_test_acc</td><td>0.91892</td></tr><tr><td>best_val_acc</td><td>0.83051</td></tr><tr><td>fold0_tmp_test_acc</td><td>0.83784</td></tr><tr><td>fold0_tmp_test_loss</td><td>0.83379</td></tr><tr><td>fold0_train_acc</td><td>1.0</td></tr><tr><td>fold0_train_loss</td><td>0.00067</td></tr><tr><td>fold0_val_acc</td><td>0.81356</td></tr><tr><td>fold0_val_loss</td><td>0.67819</td></tr><tr><td>test_acc</td><td>83.78378</td></tr><tr><td>test_acc_std</td><td>5.40541</td></tr><tr><td>val_acc</td><td>86.10169</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fallen-dawn-18</strong>: <a href=\"https://wandb.ai/sheafnn/sheafnn/runs/1o80ylz0\" target=\"_blank\">https://wandb.ai/sheafnn/sheafnn/runs/1o80ylz0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230320_190736-1o80ylz0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_acc_mean, val_acc_mean = np.mean(results, axis=0) * 100\n",
    "test_acc_std = np.sqrt(np.var(results, axis=0)[0]) * 100\n",
    "\n",
    "wandb_results = {'test_acc': test_acc_mean, 'val_acc': val_acc_mean, 'test_acc_std': test_acc_std}\n",
    "wandb.log(wandb_results)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BundleSheaf on texas | SHA: 6a21326cef112232a48ac2a9825d72c459766fc8\n",
      "Test acc: 83.7838 +/- 5.4054 | Val acc: 86.1017\n"
     ]
    }
   ],
   "source": [
    "model_name = args.model if args.evectors == 0 else f\"{args.model}+LP{args.evectors}\"\n",
    "print(f'{model_name} on {args.dataset} | SHA: {sha}')\n",
    "print(f'Test acc: {test_acc_mean:.4f} +/- {test_acc_std:.4f} | Val acc: {val_acc_mean:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]),\n",
       "  tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]),\n",
       "  tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])],\n",
       " [tensor([3, 4, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 1, 3, 3, 0, 2, 3, 3, 3, 4, 3,\n",
       "          3, 2, 0, 3, 2, 4, 4, 3, 3, 3, 3, 0, 3, 4, 3, 2, 2, 4, 3, 0, 3, 3, 3, 0,\n",
       "          4, 3, 0, 4, 2, 3, 3, 3, 0, 0, 3, 3, 3, 0, 4, 2, 3, 4, 4, 3, 3, 3, 3, 3,\n",
       "          3, 3, 0, 3, 3, 0, 0, 3, 3, 0, 3, 0, 4, 3, 3]),\n",
       "  tensor([0, 2, 3, 0, 3, 0, 3, 3, 4, 2, 0, 0, 3, 2, 3, 0, 3, 3, 4, 0, 0, 3, 3, 4,\n",
       "          3, 4, 3, 3, 0, 3, 4, 0, 3, 3, 4, 3, 0, 3, 3, 0, 4, 3, 3, 3, 3, 2, 3, 3,\n",
       "          0, 3, 0, 0, 0, 0, 4, 3, 0, 4, 3]),\n",
       "  tensor([3, 0, 3, 4, 3, 3, 3, 3, 0, 3, 3, 3, 4, 0, 0, 3, 0, 3, 3, 3, 3, 4, 0, 3,\n",
       "          3, 3, 3, 3, 0, 2, 3, 3, 3, 3, 0, 4, 3])],\n",
       " [tensor([3, 4, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 1, 3, 3, 0, 2, 3, 3, 3, 4, 3,\n",
       "          3, 2, 0, 3, 2, 4, 4, 3, 3, 3, 3, 0, 3, 4, 3, 2, 2, 4, 3, 0, 3, 3, 3, 0,\n",
       "          4, 3, 0, 4, 2, 3, 3, 3, 0, 0, 3, 3, 3, 0, 4, 2, 3, 4, 4, 3, 3, 3, 3, 3,\n",
       "          3, 3, 0, 3, 3, 0, 0, 3, 3, 0, 3, 0, 4, 3, 3]),\n",
       "  tensor([0, 3, 3, 0, 3, 0, 3, 3, 4, 2, 0, 0, 3, 2, 3, 0, 3, 3, 4, 0, 0, 3, 4, 4,\n",
       "          3, 4, 3, 3, 0, 3, 4, 0, 3, 3, 4, 3, 0, 3, 3, 0, 4, 3, 3, 3, 3, 2, 3, 3,\n",
       "          0, 3, 3, 0, 0, 0, 4, 3, 2, 4, 3]),\n",
       "  tensor([3, 3, 3, 4, 3, 3, 3, 4, 0, 3, 3, 3, 4, 0, 0, 3, 0, 3, 3, 3, 3, 4, 0, 3,\n",
       "          3, 3, 3, 3, 0, 2, 3, 3, 3, 3, 0, 4, 3])],\n",
       " [tensor([3, 4, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 1, 3, 3, 0, 2, 3, 3, 3, 4, 3,\n",
       "          3, 2, 0, 3, 2, 4, 4, 3, 3, 3, 3, 0, 3, 4, 3, 2, 2, 4, 3, 0, 3, 3, 3, 0,\n",
       "          4, 3, 0, 4, 2, 3, 3, 3, 0, 0, 3, 3, 3, 0, 4, 2, 3, 4, 4, 3, 3, 3, 3, 3,\n",
       "          3, 3, 0, 3, 3, 0, 0, 3, 3, 0, 3, 0, 4, 3, 3]),\n",
       "  tensor([0, 3, 3, 0, 3, 0, 3, 3, 4, 2, 0, 0, 3, 2, 3, 0, 3, 3, 3, 0, 2, 3, 3, 4,\n",
       "          3, 4, 3, 3, 0, 3, 4, 0, 3, 3, 3, 3, 0, 3, 3, 0, 4, 3, 3, 3, 3, 2, 3, 3,\n",
       "          0, 3, 3, 0, 0, 0, 4, 3, 2, 4, 3]),\n",
       "  tensor([3, 3, 3, 4, 3, 3, 3, 3, 0, 3, 3, 3, 4, 3, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3,\n",
       "          3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3])],\n",
       " [tensor([3, 4, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 1, 3, 3, 0, 2, 3, 3, 3, 4, 3,\n",
       "          3, 2, 0, 3, 2, 4, 4, 3, 3, 3, 3, 0, 3, 4, 3, 2, 2, 4, 3, 0, 3, 3, 3, 0,\n",
       "          4, 3, 0, 4, 2, 3, 3, 3, 0, 0, 3, 3, 3, 0, 4, 2, 3, 4, 4, 3, 3, 3, 3, 3,\n",
       "          3, 3, 0, 3, 3, 0, 0, 3, 3, 0, 3, 0, 4, 3, 3]),\n",
       "  tensor([0, 3, 3, 0, 3, 0, 3, 3, 4, 2, 0, 0, 3, 3, 3, 0, 3, 3, 3, 0, 0, 3, 3, 4,\n",
       "          3, 4, 3, 3, 0, 3, 4, 0, 3, 3, 4, 3, 0, 3, 3, 0, 4, 3, 3, 3, 3, 2, 3, 3,\n",
       "          0, 3, 3, 0, 0, 0, 4, 3, 0, 4, 3]),\n",
       "  tensor([3, 3, 3, 4, 3, 3, 3, 4, 0, 3, 3, 3, 4, 0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3,\n",
       "          3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 4, 3])]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheafnn",
   "language": "python",
   "name": "sheafnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
